{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"‡¥π‡¥≤‡µã! 2024-‡¥≤‡µÜ ‡¥Æ‡¥ø‡¥ï‡¥ö‡µç‡¥ö ‡¥µ‡µº‡¥∑‡¥Ç üòä ‚Çπ1000\" \n",
    "#text = \"Hello! How are you? üòä I have ‚Çπ1000.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡¥π‡¥≤‡µã! 2024-‡¥≤‡µÜ ‡¥Æ‡¥ø‡¥ï‡¥ö‡µç‡¥ö ‡¥µ‡µº‡¥∑‡¥Ç üòä ‚Çπ1000\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡¥π‡¥≤‡µã ‡¥≤‡µÜ ‡¥Æ‡¥ø‡¥ï‡¥ö‡µç‡¥ö ‡¥µ‡µº‡¥∑‡¥Ç  \n"
     ]
    }
   ],
   "source": [
    "cleaned_text = re.sub(r'[^\\u0D00-\\u0D7F\\u0900-\\u097F\\u0980-\\u09FF\\u0B80-\\u0BFF\\u0C00-\\u0C7F\\u0C80-\\u0CFF\\s]', '', text)\n",
    "print(cleaned_text)\n",
    "#cleaned = re.sub(r'[^A-Za-z\\s]', '' ,text)\n",
    "#print (cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['‡¥π‡¥≤‡µã', '!', '2024-‡¥≤‡µÜ', '‡¥Æ‡¥ø‡¥ï‡¥ö‡µç‡¥ö', '‡¥µ‡µº‡¥∑‡¥Ç', 'üòä', '‚Çπ1000']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "words = word_tokenize(text)\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: indicnlp in c:\\users\\hp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install indicnlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install indic-nlp-library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import indicnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indicnlp.tokenize import indic_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['‡¥π‡¥≤‡µã', '‡¥≤‡µÜ', '‡¥Æ‡¥ø‡¥ï‡¥ö‡µç‡¥ö', '‡¥µ‡µº‡¥∑‡¥Ç']\n",
      "‡¥π‡¥≤‡µã! 2024-‡¥≤‡µÜ ‡¥Æ‡¥ø‡¥ï‡¥ö‡µç‡¥ö ‡¥µ‡µº‡¥∑‡¥Ç üòä ‚Çπ1000\n"
     ]
    }
   ],
   "source": [
    "from indicnlp.tokenize import indic_tokenize\n",
    "\n",
    "words = indic_tokenize.trivial_tokenize(cleaned_text)\n",
    "print(words)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a space\n"
     ]
    }
   ],
   "source": [
    "char = \"\"  # Space character\n",
    "if char.strip():\n",
    "    print(\"Not a space\")\n",
    "else:\n",
    "    print(\"This is a space\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MALAYALAM\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "char = \"‡¥®\"  # Malayalam letter\n",
    "print(unicodedata.name(char).split()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character: ‡§®, Script: DEVANAGARI\n"
     ]
    }
   ],
   "source": [
    "char = \"‡§®\"\n",
    "script = \"DEVANAGARI\"\n",
    "print(f\"Character: {char}, Script: {script}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letter ‡¥®, script MALAYALAM\n",
      "letter ‡¥®, script MALAYALAM\n",
      "letter ‡µç, script MALAYALAM\n",
      "letter ‡¥¶, script MALAYALAM\n",
      "letter ‡¥ø, script MALAYALAM\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def extract_script(text):\n",
    "    for char in text :\n",
    "         if char.strip():\n",
    "            script = unicodedata.name(char).split()[0]\n",
    "            print(f\"letter {char}, script {script}\")\n",
    "\n",
    "text = \"‡¥®‡¥®‡µç‡¥¶‡¥ø\"\n",
    "extract_script(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Malayalam Unicode range (U+0D00 to U+0D7F)\n",
    "def contains_malayalam(text):\n",
    "    return bool(re.search(r'[\\u0D00-\\u0D7F]', text))\n",
    "\n",
    "text1 = \"‡¥ï‡µá‡¥∞‡¥≥‡¥Ç ‡¥Æ‡¥®‡µã‡¥π‡¥∞‡¥Æ‡¥æ‡¥£‡µç\"  # Malayalam text\n",
    "text2 = \"This is an English sentence.\"\n",
    "\n",
    "print(contains_malayalam(text1))  # Output: True\n",
    "print(contains_malayalam(text2))  # Output: False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Devanagari Unicode range (for both Hindi and Marathi)\n",
    "def is_devanagari(text):\n",
    "    return bool(re.search(r'[\\u0900-\\u097F]', text))\n",
    "\n",
    "text1 = \"‡§≠‡§æ‡§∞‡§§ ‡§è‡§ï ‡§∏‡•Å‡§Ç‡§¶‡§∞ ‡§¶‡•á‡§∂ ‡§π‡•à‡•§\"  # Hindi\n",
    "text2 = \"‡§Æ‡§æ‡§ù‡•á ‡§®‡§æ‡§µ ‡§∞‡§æ‡§Æ ‡§Ü‡§π‡•á.\"  # Marathi\n",
    "text3 = \"This is an English sentence.\"\n",
    "\n",
    "print(is_devanagari(text1))  # Output: True\n",
    "print(is_devanagari(text2))  # Output: True\n",
    "print(is_devanagari(text3))  # Output: False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hindi\n",
      "Marathi\n"
     ]
    }
   ],
   "source": [
    "# Define common words for Hindi and Marathi\n",
    "hindi_words = {\"‡§Æ‡•à‡§Ç\", \"‡§§‡•Å‡§Æ\", \"‡§π‡•à\", \"‡§ï‡•ç‡§Ø‡§æ\", \"‡§Æ‡•á‡§∞‡§æ\", \"‡§≠‡§æ‡§∞‡§§\", \"‡§¶‡•á‡§∂\"}\n",
    "marathi_words = {\"‡§Æ‡•Ä\", \"‡§§‡•Ç\", \"‡§Ü‡§π‡•á\", \"‡§ï‡§æ‡§Ø\", \"‡§Æ‡§æ‡§ù‡•á\", \"‡§≠‡§æ‡§∞‡§§\", \"‡§∞‡§æ‡§ú‡•ç‡§Ø\"}\n",
    "\n",
    "def detect_language(text):\n",
    "    words = set(text.split())  # Convert text into a set of words\n",
    "    hindi_count = len(words & hindi_words)  # Count Hindi words\n",
    "    marathi_count = len(words & marathi_words)  # Count Marathi words\n",
    "    \n",
    "    if hindi_count > marathi_count:\n",
    "        return \"Hindi\"\n",
    "    elif marathi_count > hindi_count:\n",
    "        return \"Marathi\"\n",
    "    else:\n",
    "        return \"Uncertain\"  # If both have equal words\n",
    "\n",
    "text1 = \"‡§≠‡§æ‡§∞‡§§ ‡§è‡§ï ‡§∏‡•Å‡§Ç‡§¶‡§∞ ‡§¶‡•á‡§∂ ‡§π‡•à‡•§\"  # Hindi sentence\n",
    "text2 = \"‡§Æ‡§æ‡§ù‡•á ‡§®‡§æ‡§µ ‡§∞‡§æ‡§Æ ‡§Ü‡§π‡•á.\"  # Marathi sentence\n",
    "\n",
    "print(detect_language(text1))  # Output: Hindi\n",
    "print(detect_language(text2))  # Output: Marathi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "marathi_suffixes = [\"‡§§‡•ã\", \"‡§§‡•á\", \"‡§§‡•Ä‡§≤\", \"‡§≤‡§æ\", \"‡§ö‡§æ\", \"‡§Æ‡§ß‡•ç‡§Ø‡•á\", \"‡§Ü‡§π‡•á\", \"‡§π‡•ã‡§§‡•á\"]\n",
    "\n",
    "def is_marathi(text):\n",
    "    words = text.split()\n",
    "    return any(word.endswith(suffix) for word in words for suffix in marathi_suffixes)\n",
    "\n",
    "text1 = \"‡§∞‡§æ‡§Æ ‡§≠‡§æ‡§∞‡§§ ‡§Æ‡•á‡§Ç ‡§∞‡§π‡§§‡§æ ‡§π‡•à‡•§\"  # Hindi\n",
    "text2 = \"‡§Æ‡•Ä ‡§™‡•Å‡§£‡•ç‡§Ø‡§æ‡§§ ‡§∞‡§æ‡§π‡§§‡•ã.\"  # Marathi\n",
    "\n",
    "print(is_marathi(text1))  # Output: False (not Marathi)\n",
    "print(is_marathi(text2))  # Output: True (Marathi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "marathi_suffixes = [\"‡§§‡•ã\", \"‡§§‡•á\", \"‡§§‡•Ä‡§≤\", \"‡§≤‡§æ\", \"‡§ö‡§æ\", \"‡§Æ‡§ß‡•ç‡§Ø‡•á\", \"‡§Ü‡§π‡•á\", \"‡§π‡•ã‡§§‡•á\"]\n",
    "\n",
    "def is_marathi(text):\n",
    "    words = text.split()\n",
    "    words = [word.strip(string.punctuation + \"‡•§\") for word in words]  # Remove punctuation\n",
    "    return any(word.endswith(suffix) for word in words for suffix in marathi_suffixes)\n",
    "\n",
    "text1 = \"‡§∞‡§æ‡§Æ ‡§≠‡§æ‡§∞‡§§ ‡§Æ‡•á‡§Ç ‡§∞‡§π‡§§‡§æ ‡§π‡•à‡•§\"  # Hindi\n",
    "text2 = \"‡§Æ‡•Ä ‡§™‡•Å‡§£‡•ç‡§Ø‡§æ‡§§ ‡§∞‡§æ‡§π‡§§‡•ã.\"  # Marathi\n",
    "\n",
    "print(is_marathi(text1))  # Output: False (not Marathi)\n",
    "print(is_marathi(text2))  # Output: True (Marathi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hindi\n",
      "Marathi\n",
      "Marathi\n",
      "Hindi\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# Define Marathi suffixes\n",
    "marathi_suffixes = [\"‡§§‡•ã\", \"‡§§‡•á\", \"‡§§‡•Ä‡§≤\", \"‡§≤‡§æ\", \"‡§ö‡§æ\", \"‡§Æ‡§ß‡•ç‡§Ø‡•á\", \"‡§Ü‡§π‡•á\", \"‡§π‡•ã‡§§‡•á\"]\n",
    "\n",
    "# Define common words for Hindi and Marathi\n",
    "hindi_words = {\"‡§Æ‡•à‡§Ç\", \"‡§§‡•Å‡§Æ\", \"‡§π‡•à\", \"‡§ï‡•ç‡§Ø‡§æ\", \"‡§Æ‡•á‡§∞‡§æ\", \"‡§≠‡§æ‡§∞‡§§\", \"‡§¶‡•á‡§∂\"}\n",
    "marathi_words = {\"‡§Æ‡•Ä\", \"‡§§‡•Ç\", \"‡§Ü‡§π‡•á\", \"‡§ï‡§æ‡§Ø\", \"‡§Æ‡§æ‡§ù‡•á\", \"‡§≠‡§æ‡§∞‡§§\", \"‡§∞‡§æ‡§ú‡•ç‡§Ø\"}\n",
    "\n",
    "def detect_language(text):\n",
    "    words = text.split()\n",
    "    words = [word.strip(string.punctuation + \"‡•§\") for word in words]  # Remove punctuation\n",
    "    \n",
    "    # Check for Marathi suffixes\n",
    "    if any(word.endswith(suffix) for word in words for suffix in marathi_suffixes):\n",
    "        return \"Marathi\"\n",
    "    \n",
    "    # Check for common words\n",
    "    words_set = set(words)\n",
    "    hindi_count = len(words_set & hindi_words)\n",
    "    marathi_count = len(words_set & marathi_words)\n",
    "    \n",
    "    if marathi_count > hindi_count:\n",
    "        return \"Marathi\"\n",
    "    elif hindi_count > marathi_count:\n",
    "        return \"Hindi\"\n",
    "    else:\n",
    "        return \"Uncertain\"  # If both have equal words or no strong indication\n",
    "\n",
    "# Test cases\n",
    "text1 = \"‡§≠‡§æ‡§∞‡§§ ‡§è‡§ï ‡§∏‡•Å‡§Ç‡§¶‡§∞ ‡§¶‡•á‡§∂ ‡§π‡•à‡•§\"  # Hindi sentence\n",
    "text2 = \"‡§Æ‡§æ‡§ù‡•á ‡§®‡§æ‡§µ ‡§∞‡§æ‡§Æ ‡§Ü‡§π‡•á.\"  # Marathi sentence\n",
    "text3 = \"‡§Æ‡•Ä ‡§™‡•Å‡§£‡•ç‡§Ø‡§æ‡§§ ‡§∞‡§æ‡§π‡§§‡•ã.\"  # Marathi sentence\n",
    "text4 = \"‡§∞‡§æ‡§Æ ‡§≠‡§æ‡§∞‡§§ ‡§Æ‡•á‡§Ç ‡§∞‡§π‡§§‡§æ ‡§π‡•à‡•§\"  # Hindi sentence\n",
    "\n",
    "print(detect_language(text1))  # Output: Hindi\n",
    "print(detect_language(text2))  # Output: Marathi\n",
    "print(detect_language(text3))  # Output: Marathi\n",
    "print(detect_language(text4))  # Output: Hindi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hindi\n",
      "Marathi\n",
      "Marathi\n",
      "Hindi\n",
      "Sanskrit\n",
      "Nepali\n",
      "Konkani\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# Define suffixes for Marathi, Sanskrit, Nepali, and Konkani\n",
    "marathi_suffixes = [\"‡§§‡•ã\", \"‡§§‡•á\", \"‡§§‡•Ä‡§≤\", \"‡§≤‡§æ\", \"‡§ö‡§æ\", \"‡§Æ‡§ß‡•ç‡§Ø‡•á\", \"‡§Ü‡§π‡•á\", \"‡§π‡•ã‡§§‡•á\"]\n",
    "sanskrit_suffixes = [\"‡§É\", \"‡§Æ‡•ç\", \"‡§É\", \"‡§Ø‡§É\", \"‡§£‡§É\"]\n",
    "nepali_suffixes = [\"‡§õ\", \"‡§≤‡•á\", \"‡§ï‡•ã\", \"‡§Æ‡§æ\", \"‡§π‡§∞‡•Å\"]\n",
    "konkani_suffixes = [\"‡§Ü‡§∏‡§æ\", \"‡§Ü‡§≤‡•á‡§Ç\", \"‡§Ü‡§≤‡•Ä\", \"‡§Ü‡§≤‡•ã\", \"‡§§‡§æ‡§§\"]\n",
    "\n",
    "# Define common words for Hindi, Marathi, Sanskrit, Nepali, and Konkani\n",
    "hindi_words = {\"‡§Æ‡•à‡§Ç\", \"‡§§‡•Å‡§Æ\", \"‡§π‡•à\", \"‡§ï‡•ç‡§Ø‡§æ\", \"‡§Æ‡•á‡§∞‡§æ\", \"‡§≠‡§æ‡§∞‡§§\", \"‡§¶‡•á‡§∂\"}\n",
    "marathi_words = {\"‡§Æ‡•Ä\", \"‡§§‡•Ç\", \"‡§Ü‡§π‡•á\", \"‡§ï‡§æ‡§Ø\", \"‡§Æ‡§æ‡§ù‡•á\", \"‡§≠‡§æ‡§∞‡§§\", \"‡§∞‡§æ‡§ú‡•ç‡§Ø\"}\n",
    "sanskrit_words = {\"‡§Ö‡§π‡§Æ‡•ç\", \"‡§§‡•ç‡§µ‡§Æ‡•ç\", \"‡§∏‡§É\", \"‡§∏‡§æ\", \"‡§ï‡§É\", \"‡§≠‡§æ‡§∞‡§§‡§Æ‡•ç\"}\n",
    "nepali_words = {\"‡§Æ\", \"‡§§‡§ø‡§Æ‡•Ä\", \"‡§õ\", \"‡§ï‡•á\", \"‡§Æ‡•á‡§∞‡•ã\", \"‡§®‡•á‡§™‡§æ‡§≤\"}\n",
    "konkani_words = {\"‡§π‡§æ‡§Ç‡§µ\", \"‡§§‡•Ç‡§Ç\", \"‡§Ü‡§∏‡§æ\", \"‡§ï‡§∂‡•á‡§Ç\", \"‡§Æ‡§æ‡§ù‡•á‡§Ç\", \"‡§≠‡§æ‡§∞‡§§\"}\n",
    "\n",
    "def detect_language(text):\n",
    "    words = text.split()\n",
    "    words = [word.strip(string.punctuation + \"‡•§\") for word in words]  # Remove punctuation\n",
    "    \n",
    "    # Check for suffixes\n",
    "    if any(word.endswith(suffix) for word in words for suffix in marathi_suffixes):\n",
    "        return \"Marathi\"\n",
    "    if any(word.endswith(suffix) for word in words for suffix in sanskrit_suffixes):\n",
    "        return \"Sanskrit\"\n",
    "    if any(word.endswith(suffix) for word in words for suffix in nepali_suffixes):\n",
    "        return \"Nepali\"\n",
    "    if any(word.endswith(suffix) for word in words for suffix in konkani_suffixes):\n",
    "        return \"Konkani\"\n",
    "    \n",
    "    # Check for common words\n",
    "    words_set = set(words)\n",
    "    hindi_count = len(words_set & hindi_words)\n",
    "    marathi_count = len(words_set & marathi_words)\n",
    "    sanskrit_count = len(words_set & sanskrit_words)\n",
    "    nepali_count = len(words_set & nepali_words)\n",
    "    konkani_count = len(words_set & konkani_words)\n",
    "    \n",
    "    # Determine the language based on word count\n",
    "    language_counts = {\n",
    "        \"Hindi\": hindi_count,\n",
    "        \"Marathi\": marathi_count,\n",
    "        \"Sanskrit\": sanskrit_count,\n",
    "        \"Nepali\": nepali_count,\n",
    "        \"Konkani\": konkani_count\n",
    "    }\n",
    "    \n",
    "    detected_language = max(language_counts, key=language_counts.get)\n",
    "    if language_counts[detected_language] > 0:\n",
    "        return detected_language\n",
    "    else:\n",
    "        return \"Uncertain\"  # If no strong indication\n",
    "\n",
    "# Test cases\n",
    "text1 = \"‡§≠‡§æ‡§∞‡§§ ‡§è‡§ï ‡§∏‡•Å‡§Ç‡§¶‡§∞ ‡§¶‡•á‡§∂ ‡§π‡•à‡•§\"  # Hindi sentence\n",
    "text2 = \"‡§Æ‡§æ‡§ù‡•á ‡§®‡§æ‡§µ ‡§∞‡§æ‡§Æ ‡§Ü‡§π‡•á.\"  # Marathi sentence\n",
    "text3 = \"‡§Æ‡•Ä ‡§™‡•Å‡§£‡•ç‡§Ø‡§æ‡§§ ‡§∞‡§æ‡§π‡§§‡•ã.\"  # Marathi sentence\n",
    "text4 = \"‡§∞‡§æ‡§Æ ‡§≠‡§æ‡§∞‡§§ ‡§Æ‡•á‡§Ç ‡§∞‡§π‡§§‡§æ ‡§π‡•à‡•§\"  # Hindi sentence\n",
    "text5 = \"‡§Ö‡§π‡§Æ‡•ç ‡§≠‡§æ‡§∞‡§§‡§Æ‡•ç ‡§ó‡§ö‡•ç‡§õ‡§æ‡§Æ‡§ø‡•§\"  # Sanskrit sentence\n",
    "text6 = \"‡§Æ‡•á‡§∞‡•ã ‡§®‡§æ‡§Æ ‡§∞‡§æ‡§Æ ‡§π‡•ã‡•§\"  # Nepali sentence\n",
    "text7 = \"‡§π‡§æ‡§Ç‡§µ ‡§ó‡•ã‡§µ‡•ç‡§Ø‡§æ‡§§ ‡§Ü‡§∏‡§æ.\"  # Konkani sentence\n",
    "\n",
    "print(detect_language(text1))  # Output: Hindi\n",
    "print(detect_language(text2))  # Output: Marathi\n",
    "print(detect_language(text3))  # Output: Marathi\n",
    "print(detect_language(text4))  # Output: Hindi\n",
    "print(detect_language(text5))  # Output: Sanskrit\n",
    "print(detect_language(text6))  # Output: Nepali\n",
    "print(detect_language(text7))  # Output: Konkani\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
